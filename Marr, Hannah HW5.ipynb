{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "\n",
    "### Name: Hannah Marr\n",
    "### Collaborator:\n",
    "\n",
    "\n",
    "DATA 201\n",
    "\n",
    "Fall 2024\n",
    "\n",
    "Tufts University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This homework explores KNN, Decision Trees, and Random Forests. The first question reviews training a KNN model. Subsequent questions provide an in-depth examination of Gini impurity and the mechanics of training a Decision Tree. Following this, we delve into basic implementations of both Decision Trees and Random Forests, accompanied by an introduction to tuning hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "(a) Load the Heart Disease dataset and name it 'df'. Conduct data cleaning.\n",
    "\n",
    "- Perform any data cleaning or data transformation steps if required\n",
    "- Explain some of the data cleaning steps which you can perform on **any** data set\n",
    "\n",
    "For clarification, please find the metadata below:\n",
    "- BPMeds: whether or not the patient was on blood pressure medication\n",
    "- prevalentStroke: whether or not the patient had previously had a stroke\n",
    "- prevalentHyp: whether or not the patient was hypertensive\n",
    "- diabetes: whether or not the patient had diabetes\n",
    "- totChol: total cholesterol level\n",
    "- sysBP: systolic blood pressure\n",
    "- diaBP: diastolic blood pressure\n",
    "- BMI: Body Mass Index\n",
    "- heartRate: heart rate\n",
    "- glucose: glucose level\n",
    "- 10 year risk of coronary heart disease CHD (binary: “1”, means “Yes”, “0” means “No”) (Predictor Variable)\n",
    "\n",
    "(b) Create two dataframes for features and target variable (TenYearCHD). Conduct a full model training and testing (30%) for a KNN model with K=5. Print the accuracy, confusion matrix, and explain what the confuison matrix tells you\n",
    "\n",
    "(c) Create a range from 1 to 50 going at steps of 2 then make a list where you will store average accuracy at each k value\n",
    "use a for loop to compute the average accuracy over 10-fold cross validation for each k value. Plot the average accuracy for each k values and determine which k value you will choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1 (a)\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"/Users/hannahmarr/Desktop/Tufts/DATA201/Heart_Disease.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q1 (a)\n",
    "Here are some common data cleaning steps that we can apply:\n",
    "1. Handling Missing Values: Check for any missing or NaN values and decide how to handle them (drop or fill with mean/median).\n",
    "2. Data Type Conversion: Ensure that columns have appropriate data types (e.g., numerical values should not be stored as strings).\n",
    "3. Outlier Detection: Identify and potentially address outliers, especially in columns like totChol, sysBP, and glucose.\n",
    "4. Standardization: Ensure consistent units, especially for medical data (e.g., cholesterol levels might need adjustments).\n",
    "5. Dropping Irrelevant Features: If some columns are not useful for analysis, they can be removed.\n",
    "6. Duplicate Rows: Check for and remove any duplicate records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Duplicate Rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>105</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currentSmoker</th>\n",
       "      <td>0</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cigsPerDay</th>\n",
       "      <td>29</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPMeds</th>\n",
       "      <td>53</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prevalentStroke</th>\n",
       "      <td>0</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prevalentHyp</th>\n",
       "      <td>0</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>0</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totChol</th>\n",
       "      <td>50</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sysBP</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diaBP</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>19</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heartRate</th>\n",
       "      <td>1</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose</th>\n",
       "      <td>388</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TenYearCHD</th>\n",
       "      <td>0</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Missing Values Data Type  Duplicate Rows\n",
       "male                          0     int64               0\n",
       "age                           0     int64               0\n",
       "education                   105   float64               0\n",
       "currentSmoker                 0     int64               0\n",
       "cigsPerDay                   29   float64               0\n",
       "BPMeds                       53   float64               0\n",
       "prevalentStroke               0     int64               0\n",
       "prevalentHyp                  0     int64               0\n",
       "diabetes                      0     int64               0\n",
       "totChol                      50   float64               0\n",
       "sysBP                         0   float64               0\n",
       "diaBP                         0   float64               0\n",
       "BMI                          19   float64               0\n",
       "heartRate                     1   float64               0\n",
       "glucose                     388   float64               0\n",
       "TenYearCHD                    0     int64               0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1 (a)\n",
    "# Performing some of the above data cleaning steps on the dataset\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Check the data types of each column\n",
    "data_types = df.dtypes\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "\n",
    "# Summary of missing values, data types, and duplicate rows\n",
    "summary = pd.DataFrame({\n",
    "    \"Missing Values\": missing_values,\n",
    "    \"Data Type\": data_types,\n",
    "    \"Duplicate Rows\": duplicate_rows\n",
    "})\n",
    "\n",
    "# Display the summary\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q1 (a)\n",
    "The dataset analysis reveals several aspects for data cleaning:\n",
    "\n",
    "1. Missing Values: Some columns, such as education, cigsPerDay, BPMeds, totChol, BMI, heartRate, and glucose, have missing values. We need to decide whether to drop these rows or fill them with appropriate values (e.g., mean or median).\n",
    "2. Data Types: The data types are mostly correct, with numerical columns identified as int64 or float64.\n",
    "3. Duplicates: No duplicate rows were found.\n",
    "\n",
    "Next, let's handle the missing values and finalize the cleaning process. I will:\n",
    "\n",
    "1. Fill missing values in numerical columns with the median.\n",
    "2. Drop rows with excessive missing data in critical columns (glucose has many missing values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male               0\n",
       "age                0\n",
       "education          0\n",
       "currentSmoker      0\n",
       "cigsPerDay         0\n",
       "BPMeds             0\n",
       "prevalentStroke    0\n",
       "prevalentHyp       0\n",
       "diabetes           0\n",
       "totChol            0\n",
       "sysBP              0\n",
       "diaBP              0\n",
       "BMI                0\n",
       "heartRate          0\n",
       "glucose            0\n",
       "TenYearCHD         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1 (a)\n",
    "# Fill missing numerical values with the median of each column\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Verify if all missing values have been handled\n",
    "cleaned_summary = df.isnull().sum()\n",
    "\n",
    "# Display the cleaned summary\n",
    "cleaned_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q1 (a)\n",
    "\n",
    "The data cleaning process is complete. All missing values have been filled using the median, and there are no remaining missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8349056603773585\n",
      "Confusion Matrix:\n",
      " [[1042   35]\n",
      " [ 175   20]]\n"
     ]
    }
   ],
   "source": [
    "#Q1 (b)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df.drop(columns=[\"TenYearCHD\"])\n",
    "y = df[\"TenYearCHD\"]\n",
    "\n",
    "# Standardize the feature data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training (70%) and testing (30%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the KNN model with K=5\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and confusion matrix\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print('Accuracy:', accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q1 (b)\n",
    "\n",
    "Model Results:\n",
    "* Accuracy: The KNN model achieved an accuracy of 83.49% on the test dataset.\n",
    "\n",
    "Confusion Matrix Explanation:\n",
    "* True Negatives (1042): The model correctly predicted 1042 instances as \"No risk\" (0) for TenYearCHD.\n",
    "* False Positives (35): The model incorrectly predicted \"Yes risk\" (1) for 35 instances that were actually \"No risk\" (0).\n",
    "* False Negatives (175): The model incorrectly predicted \"No risk\" (0) for 175 instances that were actually \"Yes risk\" (1).\n",
    "* True Positives (20): The model correctly predicted 20 instances as \"Yes risk\" (1) for TenYearCHD.\n",
    "\n",
    "The model has good performance in identifying individuals without the risk, but it struggles more with correctly identifying those who are at risk (low number of true positives). This suggests potential issues with imbalanced classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K value: 13\n"
     ]
    }
   ],
   "source": [
    "#Q1 (c)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a range of K values from 1 to 50 with steps of 2\n",
    "k_values = list(range(1, 51, 2))\n",
    "average_accuracies = []\n",
    "\n",
    "# Compute the average accuracy over 10-fold cross-validation for each K value\n",
    "for k in k_values:\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Perform 10-fold cross-validation and store the mean accuracy\n",
    "    scores = cross_val_score(knn_model, X_scaled, y, cv=10, scoring=\"accuracy\")\n",
    "    average_accuracies.append(scores.mean())\n",
    "\n",
    "# Plot the average accuracy for each K value\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, average_accuracies, marker='o')\n",
    "plt.title(\"Average Accuracy for Different K Values (KNN)\")\n",
    "plt.xlabel(\"K Value\")\n",
    "plt.ylabel(\"Average Accuracy\")\n",
    "plt.xticks(k_values)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Determine the best K value (with the highest average accuracy)\n",
    "best_k = k_values[average_accuracies.index(max(average_accuracies))]\n",
    "print('Best K value:', best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q1 (c)\n",
    "\n",
    "The plot shows the average accuracy for different K values in the KNN model. Based on the results, the best K value is the one that maximizes the average accuracy. In this case, the optimal K value is:\n",
    "\n",
    "K = 13\n",
    "\n",
    "This K value provides the highest average accuracy over 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "The goal of Q2 is to make a function that can calculate the weighted gini impurity over any grouping and any size of classes. \n",
    "\n",
    "(a) Calculate the gini impurity of the example by hand. Then write some code to do it for you. You will have to find $p_0$ and $p_1$ which are the probabilities of selecting a 0 and a 1 (respectively) from the group.\n",
    "\n",
    "(b) Now say we have two groups? Calculate the gini index of each group. Now, make a weighted sum of the gini numbers, each weighted by the proportion of the group size to the total number of entries (i.e. if group 1 is of length 10 and group 2 is of length 15, then group 1 would have a weight of 2/5 and group 2 a weight of 3/5).\n",
    "\n",
    "(c) Generalize that bit of code you wrote to now deal with any number of groups with any number of classes. Assume the groups will be given as a list of lists, and if there is an empty group the gini number will be 0 (there needs to be an if statement to make sure we do not divide by 0).\n",
    "\n",
    "(d) Make that bit of code into a function called gini_imp which takes a 'groups' variable and a 'classes' variable. It should return the gini index. Note, you need to use the classes variable because that is how you know what classes to check for in each group. Test it on the same example from part (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2 (a)\n",
    "\n",
    "###This is the example\n",
    "classes = [0,1]\n",
    "group = [0,0,0,1,1,0,1,0,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q2 (a)\n",
    "\n",
    "The Gini Impurity measures the impurity or heterogeneity of a group. It is calculated using the formula:\n",
    "\n",
    "Gini Impurity = 1 - (p0^2 + p1^2)\n",
    "\n",
    "Where:\n",
    "* p0 is the probability of selecting a 0 from the group.\n",
    "* p1 is the probability of selecting a 1 from the group.\n",
    "\n",
    "Given the group: [0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
    "* Total number of elements: n = 9\n",
    "* Number of 0's: n0 = 6\n",
    "* Number of 1's: n1 = 3\n",
    "\n",
    "Now we can find the probabilities:\n",
    "* p0 = n0/n = 6/9 = 0.6667\n",
    "* p1 = n1/n = 3/9 = 0.3333\n",
    "\n",
    "Using the formula Gini Impurity = 1 - (p0^2 + p1^2):\n",
    "* Gini Impurity = 1 - (0.6667^2 + 0.3333^2)\n",
    "* Gini Impurity = 1 - (0.4444 + 0.1111) = 1 - 0.5555 = 0.4444\n",
    "\n",
    "Thus, the Gini Impurity of the example is 0.4444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Impurity: 0.4444\n"
     ]
    }
   ],
   "source": [
    "#Q2 (a)\n",
    "# Now I will write code to automate this calculation\n",
    "def gini_impurity(group):\n",
    "    n = len(group)\n",
    "    n0 = group.count(0)\n",
    "    n1 = group.count(1)\n",
    "    \n",
    "    p0 = n0 / n\n",
    "    p1 = n1 / n\n",
    "    \n",
    "    gini = 1 - (p0 ** 2 + p1 ** 2)\n",
    "    return gini\n",
    "\n",
    "# Example group\n",
    "group = [0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
    "gini = gini_impurity(group)\n",
    "print(f\"Gini Impurity: {gini:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Gini Index: 0.4375\n"
     ]
    }
   ],
   "source": [
    "#Q2 (b)\n",
    "classes = [0,1]\n",
    "groups = [[0,0,0,1],[0,0,1,1]]\n",
    "\n",
    "def gini_impurity(group):\n",
    "    n = len(group)\n",
    "    n0 = group.count(0)\n",
    "    n1 = group.count(1)\n",
    "    \n",
    "    p0 = n0 / n\n",
    "    p1 = n1 / n\n",
    "    \n",
    "    return 1 - (p0 ** 2 + p1 ** 2)\n",
    "\n",
    "def weighted_gini_index(groups):\n",
    "    total_length = sum(len(group) for group in groups)\n",
    "    weighted_gini = 0\n",
    "    \n",
    "    for group in groups:\n",
    "        weight = len(group) / total_length\n",
    "        gini = gini_impurity(group)\n",
    "        weighted_gini += weight * gini\n",
    "    \n",
    "    return weighted_gini\n",
    "\n",
    "# Example groups\n",
    "groups = [[0, 0, 0, 1], [0, 0, 1, 1]]\n",
    "weighted_gini = weighted_gini_index(groups)\n",
    "print(f\"Weighted Gini Index: {weighted_gini:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Gini Index: 0.5684\n"
     ]
    }
   ],
   "source": [
    "#Q2 (c)\n",
    "###test your bit of code with:\n",
    "classes = [0,1,2,3]\n",
    "groups = [[0,3,1,1,1],[0,0,0,1],[2,3,1,1],[],[0,0,1,1,2,2]]\n",
    "\n",
    "def gini_impurity(group, classes):\n",
    "    n = len(group)\n",
    "    \n",
    "    # If the group is empty, return Gini impurity as 0\n",
    "    if n == 0:\n",
    "        return 0\n",
    "\n",
    "    # Calculate the probability for each class\n",
    "    probabilities = [(group.count(cls) / n) for cls in classes]\n",
    "    \n",
    "    # Compute the Gini impurity\n",
    "    gini = 1 - sum(p ** 2 for p in probabilities)\n",
    "    return gini\n",
    "\n",
    "def weighted_gini_index(groups, classes):\n",
    "    total_length = sum(len(group) for group in groups)\n",
    "    weighted_gini = 0\n",
    "    \n",
    "    # Iterate through each group and calculate its weighted Gini impurity\n",
    "    for group in groups:\n",
    "        group_length = len(group)\n",
    "        \n",
    "        # If the group is empty, skip its contribution (weight * 0 = 0)\n",
    "        if group_length == 0:\n",
    "            continue\n",
    "        \n",
    "        weight = group_length / total_length\n",
    "        gini = gini_impurity(group, classes)\n",
    "        weighted_gini += weight * gini\n",
    "    \n",
    "    return weighted_gini\n",
    "\n",
    "# Test case\n",
    "classes = [0, 1, 2, 3]\n",
    "groups = [[0, 3, 1, 1, 1], [0, 0, 0, 1], [2, 3, 1, 1], [], [0, 0, 1, 1, 2, 2]]\n",
    "\n",
    "# Calculate the weighted Gini index\n",
    "weighted_gini = weighted_gini_index(groups, classes)\n",
    "print(f\"Weighted Gini Index: {weighted_gini:.4f}\")\n",
    "\n",
    "\n",
    "###You should get a gini number equal to 0.5684"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Index: 0.5684\n"
     ]
    }
   ],
   "source": [
    "#Q2 (d)\n",
    "\n",
    "def gini_imp(groups, classes):\n",
    "    def gini_impurity(group, classes):\n",
    "        n = len(group)\n",
    "        if n == 0:\n",
    "            return 0\n",
    "        \n",
    "        # Calculate the probabilities for each class\n",
    "        probabilities = [(group.count(cls) / n) for cls in classes]\n",
    "        \n",
    "        # Compute the Gini impurity\n",
    "        gini = 1 - sum(p ** 2 for p in probabilities)\n",
    "        return gini\n",
    "\n",
    "    total_length = sum(len(group) for group in groups)\n",
    "    weighted_gini = 0\n",
    "\n",
    "    # Calculate the weighted Gini impurity for all groups\n",
    "    for group in groups:\n",
    "        group_length = len(group)\n",
    "        if group_length == 0:\n",
    "            continue\n",
    "        \n",
    "        weight = group_length / total_length\n",
    "        gini = gini_impurity(group, classes)\n",
    "        weighted_gini += weight * gini\n",
    "\n",
    "    return weighted_gini\n",
    "\n",
    "# Test case\n",
    "classes = [0, 1, 2, 3]\n",
    "groups = [[0, 3, 1, 1, 1], [0, 0, 0, 1], [2, 3, 1, 1], [], [0, 0, 1, 1, 2, 2]]\n",
    "\n",
    "# Calculate the Gini index\n",
    "gini_index = gini_imp(groups, classes)\n",
    "print(f\"Gini Index: {gini_index:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "To make a full decision trees\n",
    "\n",
    "(a) Load the datasets titanic_train_data and titanic_test_data into dataframes and split them into X_train, X_test, y_train and y_test (the training sets are coming from the titanic train data and visa versa). Note, the first two columns should be deleted because they are just passenger Id's, also documentation about the data can be found here:https://www.kaggle.com/azeembootwala/titanic. Create a Decision Tree instance, fit the data on the training sets and get the accuracy score on the test set. Report the confusion matrix.\n",
    "\n",
    "(b) Split the X_train and y_train data into sets called X_train,X_val, y_train, y_val using train_test_split. We are going to try and tune some parameters in the Decision tree. Called a new Decision Tree instance with the following parameters: **max_features, max_depth, and min_samples_leaf**. Choose some value to test them with, and run the model a few times to see if you can get different accuracy scores (use the X_val and y_val to get the accuracy scores). What do these parameters do? (Look them up in the documentation)\n",
    "\n",
    "(c) We are going to use the validation sets to try and find the best parameter combinations. So, use a triple for loop to iterate over different ranges for each of the three parameters, find what combination gives the best accuracy on the validation set. Then, use that combination on a decision tree to classify the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "Confusion Matrix:\n",
      " [[52 12]\n",
      " [ 8 28]]\n"
     ]
    }
   ],
   "source": [
    "#Q3 (a)\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Load the datasets\n",
    "train_path = \"/Users/hannahmarr/Desktop/Tufts/DATA201/titanic_train_data.csv\"\n",
    "test_path = \"/Users/hannahmarr/Desktop/Tufts/DATA201/titanic_test_data.csv\"\n",
    "\n",
    "titanic_train_data = pd.read_csv(train_path)\n",
    "titanic_test_data = pd.read_csv(test_path)\n",
    "\n",
    "# Drop the first two columns (Passenger ID and another irrelevant column)\n",
    "titanic_train_data = titanic_train_data.iloc[:, 2:]\n",
    "titanic_test_data = titanic_test_data.iloc[:, 2:]\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = titanic_train_data.drop(\"Survived\", axis=1)\n",
    "y_train = titanic_train_data[\"Survived\"]\n",
    "\n",
    "X_test = titanic_test_data.drop(\"Survived\", axis=1)\n",
    "y_test = titanic_test_data[\"Survived\"]\n",
    "\n",
    "# Create Decision Tree model and fit it\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score and confusion matrix\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Confusion Matrix:\\n', conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q3 (a)\n",
    "\n",
    "The accuracy of the Decision Tree model on the Titanic test data is 80%.\n",
    "\n",
    "This matrix indicates:\n",
    "* 52 true negatives (correctly predicted as not survived)\n",
    "* 28 true positives (correctly predicted as survived)\n",
    "* 12 false positives (incorrectly predicted as survived)\n",
    "* 8 false negatives (incorrectly predicted as not survived) ​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8050314465408805\n"
     ]
    }
   ],
   "source": [
    "#Q3 (b)\n",
    "# Import train_test_split again for validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a Decision Tree with some parameters to test\n",
    "clf_tuned = DecisionTreeClassifier(\n",
    "    max_features='sqrt',    # Testing with 'sqrt' (square root of the number of features)\n",
    "    max_depth=5,            # Setting a maximum depth of 5\n",
    "    min_samples_leaf=4,     # Minimum samples required to be at a leaf node\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "clf_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_val_pred = clf_tuned.predict(X_val)\n",
    "accuracy_val = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "print('Accuracy:', accuracy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q3 (b)\n",
    "\n",
    "With the chosen parameters (max_features='sqrt', max_depth=5, and min_samples_leaf=4), the accuracy score on the validation set is 80.5%.\n",
    "\n",
    "Explanation of the Parameters:\n",
    "* max_features: This parameter controls the number of features considered for splitting at each node. Using 'sqrt' means that the number of features is limited to the square root of the total features. This can help reduce overfitting by limiting the model's ability to fit noise in the data.\n",
    "* max_depth: This parameter sets the maximum depth of the tree. Limiting the depth can prevent the model from becoming overly complex, reducing the risk of overfitting.\n",
    "* min_samples_leaf: This defines the minimum number of samples required to be at a leaf node. By setting a higher value, we ensure that leaf nodes have more samples, which helps in creating a more generalized model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.8490566037735849\n",
      "Best Parameters: {'max_features': 'sqrt', 'max_depth': 9, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "#Q3 (c)\n",
    "# Define ranges for the parameters to be tested\n",
    "max_features_options = ['sqrt', 'log2', None]\n",
    "max_depth_options = range(3, 11)  # Testing depths from 3 to 10\n",
    "min_samples_leaf_options = range(1, 6)  # Testing minimum samples from 1 to 5\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "# Triple for loop to iterate over all combinations of the parameters\n",
    "for max_features in max_features_options:\n",
    "    for max_depth in max_depth_options:\n",
    "        for min_samples_leaf in min_samples_leaf_options:\n",
    "            # Initialize the Decision Tree with the current parameter combination\n",
    "            clf = DecisionTreeClassifier(\n",
    "                max_features=max_features,\n",
    "                max_depth=max_depth,\n",
    "                min_samples_leaf=min_samples_leaf,\n",
    "                random_state=42\n",
    "            )\n",
    "            # Fit the model on the training set\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # Evaluate on the validation set\n",
    "            y_val_pred = clf.predict(X_val)\n",
    "            accuracy_val = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "            # Check if this is the best accuracy so far\n",
    "            if accuracy_val > best_accuracy:\n",
    "                best_accuracy = accuracy_val\n",
    "                best_params = {\n",
    "                    \"max_features\": max_features,\n",
    "                    \"max_depth\": max_depth,\n",
    "                    \"min_samples_leaf\": min_samples_leaf\n",
    "                }\n",
    "\n",
    "# Output the best parameters and the best validation accuracy\n",
    "print('Best Accuracy:', best_accuracy)\n",
    "print('Best Parameters:', best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q3 (c)\n",
    "\n",
    "The best parameter combination found on the validation set is:\n",
    "* max_features: 'sqrt'\n",
    "* max_depth: 9\n",
    "* min_samples_leaf: 1\n",
    "\n",
    "This achieved a validation accuracy of 84.9%.\n",
    "\n",
    "Now, I will use this combination to fit a Decision Tree on the training data and evaluate its performance on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.84\n",
      "Test Confusion Matrix:\n",
      " [[58  6]\n",
      " [10 26]]\n"
     ]
    }
   ],
   "source": [
    "#Q3 (c)\n",
    "# Initialize the Decision Tree with the best found parameters\n",
    "best_clf = DecisionTreeClassifier(\n",
    "    max_features=best_params[\"max_features\"],\n",
    "    max_depth=best_params[\"max_depth\"],\n",
    "    min_samples_leaf=best_params[\"min_samples_leaf\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model on the entire training data\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and confusion matrix on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print('Test Accuracy:', test_accuracy)\n",
    "print('Test Confusion Matrix:\\n', test_conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q3 (c)\n",
    "\n",
    "Using the best parameter combination, the accuracy on the test set is 84%\n",
    "\n",
    "The confusion matrix indicates:\n",
    "* 58 true negatives (correctly predicted as not survived)\n",
    "* 26 true positives (correctly predicted as survived)\n",
    "* 6 false positives (incorrectly predicted as survived)\n",
    "* 10 false negatives (incorrectly predicted as not survived)\n",
    "\n",
    "This model performs well and shows an improvement after tuning the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "Let's move onto random forests, we'll be doing more parameter tuning here.\n",
    "\n",
    "(a) With the original train and test sets, run a Random Forest model on the data and report the accuracy score. How does it compare to the scores in Question 3?\n",
    "\n",
    "(b) Create the train and validation sets again, and create a Random Forest Classifier with the following parameters: **n_estimators, max_leaf_nodes, max_depth**, with some values. What do this parameters do? (Again look up the documentation) Run the model and see how the accuracy changes. Change the values and try to get a higher accuracy.\n",
    "\n",
    "(c) Similar to Question 3 part (c), use a triple for loop to iterate over combinations of parameter values for the random forest and find one that is optimal in accuracy. How does this accuracy compare to the others we have seen?\n",
    "\n",
    "Note: This kind of parameter opimization can be done using built in python functions, GridSearchCV and RandomSearchCV both are methods that take in some kind of range / distribution for the parameters and finds the best one (and uses cross validation which is a bonus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "#Q4 (a)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Reload the original datasets\n",
    "train_path_new = \"/Users/hannahmarr/Desktop/Tufts/DATA201/titanic_train_data.csv\"\n",
    "test_path_new = \"/Users/hannahmarr/Desktop/Tufts/DATA201/titanic_test_data.csv\"\n",
    "\n",
    "# Load the datasets again\n",
    "titanic_train_data = pd.read_csv(train_path_new)\n",
    "titanic_test_data = pd.read_csv(test_path_new)\n",
    "\n",
    "# Drop the first two columns (Passenger ID and another irrelevant column)\n",
    "titanic_train_data = titanic_train_data.iloc[:, 2:]\n",
    "titanic_test_data = titanic_test_data.iloc[:, 2:]\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = titanic_train_data.drop(\"Survived\", axis=1)\n",
    "y_train = titanic_train_data[\"Survived\"]\n",
    "\n",
    "X_test = titanic_test_data.drop(\"Survived\", axis=1)\n",
    "y_test = titanic_test_data[\"Survived\"]\n",
    "\n",
    "# Initialize and fit the Random Forest model\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_rf_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "rf_accuracy = accuracy_score(y_test, y_test_rf_pred)\n",
    "\n",
    "print('Random Forest Accuracy:', rf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q4 (a)\n",
    "\n",
    "Using the original train and test sets, the Random Forest model achieved an accuracy of 85% on the test set.\n",
    "\n",
    "Comparison:\n",
    "* Random Forest: 85% accuracy\n",
    "* Tuned Decision Tree: 84% accuracy\n",
    "* Untuned Decision Tree: 80% accuracy\n",
    "\n",
    "\n",
    "The Random Forest slightly outperformed the Decision Tree models, highlighting its strength as an ensemble method that reduces variance and typically offers better generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Validation Accuracy: 0.8427672955974843\n"
     ]
    }
   ],
   "source": [
    "#Q4 (b)\n",
    "# Import the necessary module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the original training data into new training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest model with some parameters\n",
    "rf_clf_tuned = RandomForestClassifier(\n",
    "    n_estimators=150,        # Number of trees in the forest\n",
    "    max_leaf_nodes=20,       # Maximum number of leaf nodes per tree\n",
    "    max_depth=10,            # Maximum depth of each tree\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_clf_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_val_rf_pred = rf_clf_tuned.predict(X_val)\n",
    "rf_val_accuracy = accuracy_score(y_val, y_val_rf_pred)\n",
    "\n",
    "print('Random Forest Validation Accuracy:', rf_val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q4 (b)\n",
    "\n",
    "With the specified parameters (n_estimators=150, max_leaf_nodes=20, and max_depth=10), the accuracy on the validation set is 84.3%.\n",
    "\n",
    "Explanation of the Parameters:\n",
    "* n_estimators: This is the number of trees in the Random Forest. More trees generally improve performance but also increase computation time.\n",
    "* max_leaf_nodes: This limits the number of leaf nodes per tree, preventing overly complex trees and reducing the risk of overfitting.\n",
    "* max_depth: This sets the maximum depth of each tree. Limiting the depth helps control the complexity of the model and can prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Accuracy: 0.8427672955974843\n",
      "Best Random Forest Parameters: {'n_estimators': 50, 'max_leaf_nodes': 10, 'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "#Q4 (c)\n",
    "# Define ranges for the parameters to be tested\n",
    "n_estimators_options = [50, 100, 150, 200]\n",
    "max_leaf_nodes_options = [10, 20, 30, None]\n",
    "max_depth_options = [5, 10, 15, None]\n",
    "\n",
    "best_rf_accuracy = 0\n",
    "best_rf_params = {}\n",
    "\n",
    "# Triple for loop to iterate over all combinations of the parameters\n",
    "for n_estimators in n_estimators_options:\n",
    "    for max_leaf_nodes in max_leaf_nodes_options:\n",
    "        for max_depth in max_depth_options:\n",
    "            # Initialize the Random Forest with the current parameter combination\n",
    "            rf_clf = RandomForestClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                max_leaf_nodes=max_leaf_nodes,\n",
    "                max_depth=max_depth,\n",
    "                random_state=42\n",
    "            )\n",
    "            # Fit the model on the training data\n",
    "            rf_clf.fit(X_train, y_train)\n",
    "\n",
    "            # Evaluate on the validation set\n",
    "            y_val_pred = rf_clf.predict(X_val)\n",
    "            accuracy_val = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "            # Check if this is the best accuracy so far\n",
    "            if accuracy_val > best_rf_accuracy:\n",
    "                best_rf_accuracy = accuracy_val\n",
    "                best_rf_params = {\n",
    "                    \"n_estimators\": n_estimators,\n",
    "                    \"max_leaf_nodes\": max_leaf_nodes,\n",
    "                    \"max_depth\": max_depth\n",
    "                }\n",
    "\n",
    "# Output the best parameters and the best validation accuracy\n",
    "print('Best Random Forest Accuracy:', best_rf_accuracy)\n",
    "print('Best Random Forest Parameters:', best_rf_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q4 (c)\n",
    "\n",
    "The best parameter combination found for the Random Forest on the validation set is:\n",
    "* n_estimators: 50\n",
    "* max_leaf_nodes: 10\n",
    "* max_depth: 5\n",
    "\n",
    "This achieved a validation accuracy of 84.3%.\n",
    "\n",
    "Comparison:\n",
    "* Untuned Decision Tree: 80% accuracy\n",
    "* Tuned Decision Tree: 84% accuracy\n",
    "* Untuned Random Forest: 85% accuracy\n",
    "* Tuned Random Forest: 84.3% accuracy\n",
    "\n",
    "In this case, the untuned Random Forest slightly outperformed the tuned versions of both models. This could be due to the simplicity of the dataset, where extensive tuning might not provide additional benefits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus\n",
    "\n",
    "Come up with an analogy for decision tree's v. random forest's and why random forests avoid the problem of overfitting. (+5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of a Decision Tree as a single judge in a courtroom making a ruling based solely on their own perspective. If this judge has a lot of information (i.e., no restrictions like max_depth), they may try to account for every tiny detail, even if those details are just noise or anomalies. This leads to overfitting — making a decision based on specifics that might not apply in general cases.\n",
    "\n",
    "Now imagine a Random Forest as a panel of judges, where each judge gets only a random subset of the evidence (features) and makes their ruling independently. The panel then takes a vote on the final decision. Because each judge sees different parts of the case and they all contribute equally, the final verdict is a blend of their opinions. This process reduces the risk of overfitting because:\n",
    "\n",
    "Diverse Opinions: By giving each judge (tree) different evidence (features), we prevent any single judge from becoming too specific to the details (noise) of a particular case.\n",
    "\n",
    "Averaging Effect: The ensemble decision (average of all trees' predictions) is more robust, reducing the impact of any one judge that might have made a biased or overfitted decision.\n",
    "\n",
    "In essence, a Random Forest is like a team of experts who make more balanced and general decisions than any single expert could on their own. This leads to better generalization on unseen data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
